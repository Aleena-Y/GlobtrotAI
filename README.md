# ğŸŒ GlobtrotAI

**AI-Powered Country Recommender for Global Opportunities**

GlobtrotAI is an intelligent AI system that recommends **the best countries to pursue your goals** â€” whether in **education, research, or innovation** â€” using a **Retrieval-Augmented Generation (RAG)** pipeline powered by **Ollama (Gemma 3:1B)** and **FAISS-based semantic search**.

---

## ğŸ§­ Overview

GlobtrotAI connects a **FastAPI backend** (for inference and data retrieval) with a **React frontend** (for user interaction).
The system uses **Gemma 3:1B** locally via Ollama to generate context-aware, explainable country recommendations.

---

## ğŸš€ Features

* ğŸ” **RAG with FAISS** â€“ Retrieves relevant country data for precise recommendations.
* ğŸ§  **Local LLM (Gemma 3:1B)** â€“ Fast, lightweight reasoning via Ollama.
* ğŸ§© **Explainable Output** â€“ Every recommendation comes with a short rationale.
* ğŸ§­ **Interactive Web UI** â€“ Simple chat interface built in React.
* âš™ï¸ **Modular Architecture** â€“ Easy to plug in new datasets or domains.

---

## ğŸ—ï¸ Project Structure

```
GlobtrotAI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                  # FastAPI backend
â”‚   â”œâ”€â”€ rag_pipeline.py         # Retrieval-Augmented Generation logic
â”‚   â”œâ”€â”€ generate_embeddings.py  # Embedding generation script
â”‚   â”œâ”€â”€ query_ollama.py         # Handles requests to Ollama API
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ countries.json
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatBox.jsx
â”‚   â”‚   â”‚   â””â”€â”€ CountryCard.jsx
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â””â”€â”€ client.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ embeddings/                 # FAISS index files
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/<your-username>/GlobtrotAI.git
cd GlobtrotAI
```

---

### 2. Backend Setup

#### Create Virtual Environment

```bash
cd backend
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

#### Install Requirements

```bash
pip install -r requirements.txt
```

#### Example `requirements.txt`

```
fastapi
uvicorn
faiss-cpu
sentence-transformers
requests
pydantic
```

---

### 3. Install and Configure Ollama

#### Install Ollama

Download from [https://ollama.ai](https://ollama.ai) and install.

#### Pull the Gemma Model

```bash
ollama pull gemma:1b
```

#### Run Ollama in Background

```bash
ollama serve
```

Confirm itâ€™s working:

```bash
curl http://localhost:11434/api/generate -d '{"model":"gemma:1b","prompt":"Hello"}'
```

---

### 4. Generate Embeddings

Before first use, embed your dataset:

```bash
python generate_embeddings.py
```

This creates a FAISS index in `/embeddings`.

---

### 5. Run FastAPI Backend

```bash
uvicorn app:app --reload
```

API will run on `http://localhost:8000`

Example endpoint:

```
POST /recommend
{
  "query": "Which country is best for space research?"
}
```

---

### 6. Frontend Setup (React)

```bash
cd ../frontend
npm install
npm run dev
```

Frontend runs at `http://localhost:5173` (Vite default).

Make sure the API URL in `client.js` points to `http://localhost:8000`.

---

## ğŸ§  Example Prompt

```
User: Suggest countries suitable for renewable energy startups.
```

**GlobtrotAI Output:**

> â€œGermany and Denmark lead in clean energy innovation.
> Germanyâ€™s research funding is high, while Denmark supports small-scale energy ventures.â€

---

## ğŸ”„ API Endpoints

| Method | Endpoint     | Description                             |
| ------ | ------------ | --------------------------------------- |
| POST   | `/recommend` | Generates country recommendations       |
| GET    | `/health`    | Verifies server and Ollama connectivity |
| POST   | `/embed`     | Regenerates FAISS embeddings            |

---

## ğŸ§° Troubleshooting

**1. Ollama not returning any output?**
Run:

```bash
ollama serve
```

and test:

```bash
curl http://localhost:11434/api/generate -d '{"model":"gemma:1b","prompt":"test"}'
```

**2. Backend gives empty results?**
Ensure FAISS index exists and embeddings are generated correctly.

**3. Frontend canâ€™t reach backend?**
Open `/frontend/src/api/client.js` and confirm:

```js
const BASE_URL = "http://localhost:8000";
```

---

## ğŸ›£ï¸ Roadmap

* [ ] Add country scoring visualization dashboard
* [ ] Integrate real-time global datasets (research output, cost of living, etc.)
* [ ] Deploy on Docker and connect to cloud Ollama servers
* [ ] Add authentication for user profiles

---

## ğŸ§¾ License

Licensed under the **MIT License** â€” free to modify, use, and build upon.

---

## âœ¨ Author

**Aleena Yogindar**
Engineering Student @ VIT Chennai
Building systems that make AI think globally and recommend intelligently.
